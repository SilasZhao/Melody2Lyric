{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79987267-136c-4980-8a10-ff987648dacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'sentence': 'To this day when I hear that song I think of you', 'tie_pos': (10,), 'total_and_incorrect': (4, 1)}]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import pickle\n",
    "from peft import PeftModel\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    ")\n",
    "import sys\n",
    "from inference_util import *\n",
    "sys.path.append(\"/home/songyan/Real_M2L-main/llama/\")\n",
    "from over_sample_reject import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6c97cf3-f410-4ffe-a3e7-fa56ac0fa6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\"\n",
    "# MODEL_NAME = \"NousResearch/Llama-2-7b-chat-hf\"\n",
    "MODEL_NAME = \"NousResearch/Llama-2-13b-chat-hf\"\n",
    "# OUTPUT_DIR = \"/home/songyan/Real_M2L-main/finetune_llama/Finetune-Llama2-LoRA-main/out_with_negative_13b/checkpoint-23328\"\n",
    "# OUTPUT_DIR = \"/data1/songyan/M2L/lyric/llama13b/with_negative/with_gpt_data/with_song_struct/checkpoint-11625/\"\n",
    "OUTPUT_DIR = \"zzzsssyyy/Llama13bRevisingWithStruct\"\n",
    "SOURCE_FILE = \"/home/songyan/Real_M2L-main/data/data_finetune/eval/end-to-end-data/song_4_2.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "930b861d-1c93-4536-9541-2095be064d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████| 3/3 [00:06<00:00,  2.31s/it]\n",
      "Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████| 3/3 [00:08<00:00,  2.71s/it]\n"
     ]
    }
   ],
   "source": [
    "DEFAULT_SYSTEM_PROMPT = \"\"\"\n",
    "Below is the lyric of a song and the constraint. Rewrite the lyric to satisfy the constraint.\n",
    "\"\"\".strip()\n",
    "def get_input(f_names):\n",
    "    all_lyrics = []\n",
    "    lyric = \"\"\n",
    "    for f_name in f_names:\n",
    "        with open(f_name, 'r') as file:\n",
    "            for line in file:\n",
    "                # print(line)\n",
    "                # Check each line against the pattern\n",
    "                if \"[\" in line and \"]\" in line:\n",
    "                    all_lyrics.append({\"lyric\":lyric.strip(),\"constraint\":eval(line.strip())})\n",
    "                else:\n",
    "                    lyric = line\n",
    "    return all_lyrics\n",
    "def generate_prompt(input, system_prompt = DEFAULT_SYSTEM_PROMPT):\n",
    "   return f\"\"\"\n",
    "          ### Instruction: {system_prompt}\n",
    "   \n",
    "          ### Input:\n",
    "          {input}\n",
    "\n",
    "          ### Response:\n",
    "          \"\"\".strip()\n",
    "\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.float16,\n",
    "    )\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        use_safetensors=True,\n",
    "        quantization_config=bnb_config,\n",
    "        trust_remote_code=True,\n",
    "        device_map=\"auto\",\n",
    "        cache_dir='/local1/songyan/cache',\n",
    "\n",
    ")\n",
    "rephrase_model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        use_safetensors=True,\n",
    "        quantization_config=bnb_config,\n",
    "        trust_remote_code=True,\n",
    "        device_map=\"auto\",\n",
    "        cache_dir='/local1/songyan/cache',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3391575-1980-4f3e-a7b6-128acb04def9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Apr  6 22:40:00 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM4-40GB          On  | 00000000:01:00.0 Off |                    0 |\n",
      "| N/A   31C    P0              68W / 400W |  26142MiB / 40960MiB |     31%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100-SXM4-40GB          On  | 00000000:41:00.0 Off |                    0 |\n",
      "| N/A   33C    P0              86W / 400W |  33400MiB / 40960MiB |     17%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100-SXM4-40GB          On  | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   28C    P0              95W / 400W |  33994MiB / 40960MiB |     15%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A100-SXM4-40GB          On  | 00000000:C1:00.0 Off |                    0 |\n",
      "| N/A   29C    P0              73W / 400W |  15732MiB / 40960MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A   2951378      C   python                                    26128MiB |\n",
      "|    1   N/A  N/A   2951252      C   python                                    33386MiB |\n",
      "|    2   N/A  N/A   2935908      C   python                                    33980MiB |\n",
      "|    3   N/A  N/A   3070286      C   .../anaconda3/envs/finetune/bin/python    15718MiB |\n",
      "+---------------------------------------------------------------------------------------+\n",
      "WARNING: infoROM is corrupted at gpu 0000:01:00.0\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77067cc9-3c30-48ca-82d5-a053335d739b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db905e46-123c-47c2-a045-71775e9ca071",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prefix_prompt_longer = \"\"\"[INST]<<SYS>> You are a professional writer who is good at rephrasing sentences <</SYS>>\n",
    "Rewrite a lyric line by adding some trivial details. Make the sentence longer. You should compose two rephrased sentences for the input lyrics. \n",
    "\n",
    "Lyrics to be rephrased: \n",
    "Dreamers seek mysteries.\n",
    "[/INST]\n",
    "Original: \"Dreamers seek mysteries.\"\n",
    "Rephrased1:\"Visionaries pursue enigmas, yearning for discovery. \"\n",
    "Rephrased2: \"Wanderers chase after the unknown, drawn by curiosity.\"\n",
    "\n",
    "[INST]<<SYS>> You are a professional writer who is good at rephrasing sentences <</SYS>>\n",
    "Rewrite a lyric line by adding some trivial details. Make the sentence longer. You should compose two rephrased sentences for the input lyrics. \n",
    "\n",
    "Lyrics to be rephrased: \n",
    "I've spent my life shining shoes at the station.\n",
    "[/INST]\n",
    "Original: \"I've spent my life shining shoes at the station.\"\n",
    "Rephrased1: \"My days have been devoted to polishing footwear in the hustle of the terminal.\"\n",
    "Rephrased2: \"Life passed, buffing boots amidst the commotion of the station.\"\n",
    "\n",
    "[INST]<<SYS>> You are a professional writer who is good at rephrasing sentences <</SYS>>\n",
    "Rewrite a lyric line by adding some trivial details. Make the sentence longer. You should compose two rephrased sentences for the input lyrics. \n",
    "\n",
    "Lyrics to be rephrased: \n",
    "Began at nine, learning alone.\n",
    "[/INST]\n",
    "Original: \"Began at nine, learning alone.\"\n",
    "Rephrased1: \"Started at dawn's light, mastering skills in solitude.\"\n",
    "Rephrased2: \"Commenced when the clock struck nine, self-taught in silence.\"\n",
    "\n",
    "[INST]<<SYS>> You are a professional writer who is good at rephrasing sentences <</SYS>> \n",
    "Rewrite a lyric line by adding some trivial details. Make the sentence longer. You should compose two rephrased sentences for the input lyrics. \n",
    "\n",
    "Lyrics to be rephrased: \n",
    "\"\"\"\n",
    "prefix_prompt_shorter = \"\"\"[INST]<<SYS>> You are a professional writer who is good at rephrasing sentences <</SYS>>\n",
    "Rewrite a lyric line by deleting some trivial details. Make the sentence shorter. You should compose two rephrased sentences for the input lyrics. \n",
    "\n",
    "Lyrics to be rephrased: \n",
    "Many people while away their time fantasizing about uncovering mysteries\n",
    "[/INST]\n",
    "Original: \"Many people while away their time fantasizing about uncovering mysteries.\"\n",
    "Rephrased1:\"Many dream of solving mysteries.\"\n",
    "Rephrased2: \"Dreamers seek mysteries.\"\n",
    "\n",
    "[INST]<<SYS>> You are a professional writer who is good at rephrasing sentences <</SYS>>\n",
    "Rewrite a lyric line by deleting some trivial details. Make the sentence shorter. You should compose two rephrased sentences for the input lyrics. \n",
    "\n",
    "Lyrics to be rephrased: \n",
    "I've been stationed here at the railway station, polishing footwear\n",
    "[/INST]\n",
    "Original: \"I've been stationed here at the railway station, polishing footwear\"\n",
    "Rephrased1: \"Stationed at the rail, shining shoes.\"\n",
    "Rephrased2: \"At the station, polishing shoes.\"\n",
    "\n",
    "[INST]<<SYS>> You are a professional writer who is good at rephrasing sentences <</SYS>>\n",
    "Rewrite a lyric line by deleting some trivial details. Make the sentence shorter. You should compose two rephrased sentences for the input lyrics. \n",
    "\n",
    "Lyrics to be rephrased: \n",
    "I started when I was nine, on my own and taught myself\n",
    "[/INST]\n",
    "Original: \"I started when I was nine, on my own and taught myself\"\n",
    "Rephrased1: \"Started at nine, self-taught.\"\n",
    "Rephrased2: \"Began at nine, learning alone.\"\n",
    "\n",
    "[INST]<<SYS>> You are a professional writer who is good at rephrasing sentences <</SYS>> \n",
    "Rewrite a lyric line by deleting some trivial details. Make the sentence shorter. You should compose two rephrased sentences for the input lyrics. \n",
    "\n",
    "Lyrics to be rephrased: \n",
    "\"\"\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "new_tokens = ['/STRESSED/', '/UNSTRESSED/']#/UNSTRESSED/-/STRESSED/\n",
    "new_tokens = set(new_tokens) - set(tokenizer.vocab.keys())\n",
    "tokenizer.add_tokens(list(new_tokens))\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model = PeftModel.from_pretrained(model, OUTPUT_DIR,cache_dir='/local1/songyan/cache')\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5ff859c-10cc-44e3-bda3-4d72725aea78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): PeftModelForCausalLM(\n",
       "      (base_model): LoraModel(\n",
       "        (model): PeftModelForCausalLM(\n",
       "          (base_model): LoraModel(\n",
       "            (model): LlamaForCausalLM(\n",
       "              (model): LlamaModel(\n",
       "                (embed_tokens): Embedding(32003, 5120)\n",
       "                (layers): ModuleList(\n",
       "                  (0-39): 40 x LlamaDecoderLayer(\n",
       "                    (self_attn): LlamaSdpaAttention(\n",
       "                      (q_proj): lora.Linear4bit(\n",
       "                        (base_layer): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
       "                        (lora_dropout): ModuleDict(\n",
       "                          (default): Dropout(p=0.1, inplace=False)\n",
       "                        )\n",
       "                        (lora_A): ModuleDict(\n",
       "                          (default): Linear(in_features=5120, out_features=16, bias=False)\n",
       "                        )\n",
       "                        (lora_B): ModuleDict(\n",
       "                          (default): Linear(in_features=16, out_features=5120, bias=False)\n",
       "                        )\n",
       "                        (lora_embedding_A): ParameterDict()\n",
       "                        (lora_embedding_B): ParameterDict()\n",
       "                      )\n",
       "                      (k_proj): lora.Linear4bit(\n",
       "                        (base_layer): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
       "                        (lora_dropout): ModuleDict(\n",
       "                          (default): Dropout(p=0.1, inplace=False)\n",
       "                        )\n",
       "                        (lora_A): ModuleDict(\n",
       "                          (default): Linear(in_features=5120, out_features=16, bias=False)\n",
       "                        )\n",
       "                        (lora_B): ModuleDict(\n",
       "                          (default): Linear(in_features=16, out_features=5120, bias=False)\n",
       "                        )\n",
       "                        (lora_embedding_A): ParameterDict()\n",
       "                        (lora_embedding_B): ParameterDict()\n",
       "                      )\n",
       "                      (v_proj): lora.Linear4bit(\n",
       "                        (base_layer): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
       "                        (lora_dropout): ModuleDict(\n",
       "                          (default): Dropout(p=0.1, inplace=False)\n",
       "                        )\n",
       "                        (lora_A): ModuleDict(\n",
       "                          (default): Linear(in_features=5120, out_features=16, bias=False)\n",
       "                        )\n",
       "                        (lora_B): ModuleDict(\n",
       "                          (default): Linear(in_features=16, out_features=5120, bias=False)\n",
       "                        )\n",
       "                        (lora_embedding_A): ParameterDict()\n",
       "                        (lora_embedding_B): ParameterDict()\n",
       "                      )\n",
       "                      (o_proj): lora.Linear4bit(\n",
       "                        (base_layer): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
       "                        (lora_dropout): ModuleDict(\n",
       "                          (default): Dropout(p=0.1, inplace=False)\n",
       "                        )\n",
       "                        (lora_A): ModuleDict(\n",
       "                          (default): Linear(in_features=5120, out_features=16, bias=False)\n",
       "                        )\n",
       "                        (lora_B): ModuleDict(\n",
       "                          (default): Linear(in_features=16, out_features=5120, bias=False)\n",
       "                        )\n",
       "                        (lora_embedding_A): ParameterDict()\n",
       "                        (lora_embedding_B): ParameterDict()\n",
       "                      )\n",
       "                      (rotary_emb): LlamaRotaryEmbedding()\n",
       "                    )\n",
       "                    (mlp): LlamaMLP(\n",
       "                      (gate_proj): lora.Linear4bit(\n",
       "                        (base_layer): Linear4bit(in_features=5120, out_features=13824, bias=False)\n",
       "                        (lora_dropout): ModuleDict(\n",
       "                          (default): Dropout(p=0.1, inplace=False)\n",
       "                        )\n",
       "                        (lora_A): ModuleDict(\n",
       "                          (default): Linear(in_features=5120, out_features=16, bias=False)\n",
       "                        )\n",
       "                        (lora_B): ModuleDict(\n",
       "                          (default): Linear(in_features=16, out_features=13824, bias=False)\n",
       "                        )\n",
       "                        (lora_embedding_A): ParameterDict()\n",
       "                        (lora_embedding_B): ParameterDict()\n",
       "                      )\n",
       "                      (up_proj): lora.Linear4bit(\n",
       "                        (base_layer): Linear4bit(in_features=5120, out_features=13824, bias=False)\n",
       "                        (lora_dropout): ModuleDict(\n",
       "                          (default): Dropout(p=0.1, inplace=False)\n",
       "                        )\n",
       "                        (lora_A): ModuleDict(\n",
       "                          (default): Linear(in_features=5120, out_features=16, bias=False)\n",
       "                        )\n",
       "                        (lora_B): ModuleDict(\n",
       "                          (default): Linear(in_features=16, out_features=13824, bias=False)\n",
       "                        )\n",
       "                        (lora_embedding_A): ParameterDict()\n",
       "                        (lora_embedding_B): ParameterDict()\n",
       "                      )\n",
       "                      (down_proj): lora.Linear4bit(\n",
       "                        (base_layer): Linear4bit(in_features=13824, out_features=5120, bias=False)\n",
       "                        (lora_dropout): ModuleDict(\n",
       "                          (default): Dropout(p=0.1, inplace=False)\n",
       "                        )\n",
       "                        (lora_A): ModuleDict(\n",
       "                          (default): Linear(in_features=13824, out_features=16, bias=False)\n",
       "                        )\n",
       "                        (lora_B): ModuleDict(\n",
       "                          (default): Linear(in_features=16, out_features=5120, bias=False)\n",
       "                        )\n",
       "                        (lora_embedding_A): ParameterDict()\n",
       "                        (lora_embedding_B): ParameterDict()\n",
       "                      )\n",
       "                      (act_fn): SiLU()\n",
       "                    )\n",
       "                    (input_layernorm): LlamaRMSNorm()\n",
       "                    (post_attention_layernorm): LlamaRMSNorm()\n",
       "                  )\n",
       "                )\n",
       "                (norm): LlamaRMSNorm()\n",
       "              )\n",
       "              (lm_head): Linear(in_features=5120, out_features=32003, bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23303a65-84d7-4ed2-84b7-ed5645def027",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(lyrics,constraint,title,history_info):\n",
    "    Input = create_input(lyrics,constraint,title) if history_info == \"\" else create_input(lyrics,constraint,title,history_info)\n",
    "    print(f'Input created: \\n {Input}')\n",
    "    res = generate(model, generate_prompt(Input)+\"\\n          We want to generate a lyric with\")\n",
    "    item = {\"prompt\": Input, \"res\": res}\n",
    "    print(res)\n",
    "    res_sentence, mapping,total_and_incorrect = get_result_from_over_generation(item)\n",
    "    print(f'res_sentence {res_sentence}, mapping {mapping} total_and_incorrect {total_and_incorrect}')\n",
    "    return res_sentence,mapping,total_and_incorrect\n",
    "def get_valid_pair(results):\n",
    "    paired_lines = []\n",
    "    for result in results:\n",
    "        l = result.strip().split('\\n')\n",
    "        \n",
    "        # print(result)\n",
    "        # exit()\n",
    "        # Iterating through the lines to find \"Original\" and \"Rephrased\" pairs\n",
    "        for j in range(len(l) - 2):\n",
    "            if l[j].strip().startswith('Original:') and l[j + 1].strip().startswith('Rephrased1:') and l[j + 2].strip().startswith('Rephrased2:'):\n",
    "                original_line = l[j].strip()\n",
    "                original_line = original_line.replace('\"', '')\n",
    "                original_line = original_line.replace('Original:', '')\n",
    "                original_line = original_line.strip()\n",
    "                rephrased_line_1 = l[j + 1].strip()\n",
    "                rephrased_line_1 = rephrased_line_1.replace('\"', '')\n",
    "                rephrased_line_1 = rephrased_line_1.replace('Rephrased1:', '')\n",
    "                rephrased_line_1 = rephrased_line_1.strip()\n",
    "                rephrased_line_2 = l[j + 2].strip()\n",
    "                rephrased_line_2 = rephrased_line_2.replace('\"', '')\n",
    "                rephrased_line_2 = rephrased_line_2.replace('Rephrased2:', '')\n",
    "                rephrased_line_2 = rephrased_line_2.strip()\n",
    "            \n",
    "                paired_lines.append({\"Original\":original_line, \"Rephrased1\":rephrased_line_1,\"Rephrased2\":rephrased_line_2})\n",
    "        return paired_lines\n",
    "def get_rephrased_sentence(original,constraint):\n",
    "    num_sy,_ = extract(original)\n",
    "    if num_sy > len(constraint):\n",
    "        prompt = prefix_prompt_shorter + original +\"\\n\" + \"[/INST]\"\n",
    "    else:\n",
    "        prompt = prefix_prompt_longer+ original +\"\\n\" + \"[/INST]\"\n",
    "    results = generate(model, prompt,max_new_tokens=150)\n",
    "    pair = get_valid_pair(results)\n",
    "    if pair == []:\n",
    "        print(f'failed get the rephrased sentence.')\n",
    "        print(f'ourput {results}')\n",
    "        return None\n",
    "    else:\n",
    "        rephrased1, rephrased2 = pair[0][\"Rephrased1\"], pair[0][\"Rephrased2\"]\n",
    "        num_syllable1,_ = extract(rephrased1)\n",
    "        num_syllable2,_ = extract(rephrased2)\n",
    "        if abs(num_syllable1 - len(constraint)) <= abs(num_syllable2 - len(constraint)):\n",
    "            rephrased = rephrased1\n",
    "        else:\n",
    "            rephrased = rephrased2\n",
    "        return rephrased\n",
    "def generate(model, prompt,max_new_tokens = 50):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(DEVICE)\n",
    "    inputs_length = len(inputs[\"input_ids\"][0])\n",
    "    with torch.inference_mode():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=max_new_tokens,num_beams=16,num_return_sequences = 16,num_beam_groups = 16,diversity_penalty = 1.2)\n",
    "    # print(f'outputs shape is {outputs.shape}')\n",
    "    # print([tokenizer.decode(out[inputs_length:], skip_special_tokens=True) for out in outputs])\n",
    "    # print(tokenizer.decode(outputs[inputs_length:], skip_special_tokens=True))\n",
    "    \n",
    "    return [tokenizer.decode(out[inputs_length:], skip_special_tokens=True) for out in outputs]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8525ddb2-963c-4da9-ae96-a5de997b18a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_songs(out_f,iteration = 5):\n",
    "    with open(SOURCE_FILE,'r') as f:\n",
    "        data = json.load(f)\n",
    "    save_res = []\n",
    "    for song in data:\n",
    "        constraints = song[\"constraints\"]\n",
    "        lyrics = song[\"lyrics\"]\n",
    "        title = song[\"title\"]\n",
    "        lyrics = lyrics.split(\"\\n\")\n",
    "        history_info = \"\"\n",
    "        for num_line in range(len(lyrics)):\n",
    "\n",
    "            res_sentence, mapping,total_and_incorrect = get_result(lyrics[num_line],constraints[num_line],title,history_info)\n",
    "            if res_sentence is not None:\n",
    "                save_res.append({\"original\":lyrics[num_line],\"constraint\":constraints[num_line],\"result_sentence\":res_sentence,\"mapping\":mapping,\"total_and_incorrect\":total_and_incorrect,\"title\":title})\n",
    "            else:\n",
    "                i = 0\n",
    "                rephrased = get_rephrased_sentence(lyrics[num_line],constraints[num_line])\n",
    "                \n",
    "                while res_sentence is None and i < iteration:\n",
    "                    if rephrased == None:\n",
    "                        print(f'rephrased is None!!')\n",
    "                        save_res.append({\"original\":lyrics[num_line],\"constraint\":constraints[num_line],\"result_sentence\":None,\"mapping\":None,\"total_and_incorrect\":None,\"title\":title})\n",
    "                        break\n",
    "\n",
    "                    print(f'rephrased sentence {rephrased}')\n",
    "                    res_sentence, mapping,total_and_incorrect = get_result(rephrased,constraints[num_line],title,history_info)\n",
    "                    i += 1\n",
    "                    if res_sentence is None:\n",
    "                        rephrased = get_rephrased_sentence(rephrased,constraints[num_line])\n",
    "                if res_sentence is not None:\n",
    "                    save_res.append({\"original\":lyrics[num_line],\"constraint\":constraints[num_line],\"result_sentence\":res_sentence,\"mapping\":mapping,\"total_and_incorrect\":total_and_incorrect,\"title\":title})\n",
    "            if res_sentence is not None:\n",
    "                history_info += re.sub(r'[!.,;:?\"]+\\s*$', '', res_sentence) + \", \"\n",
    "            out_f = out_f\n",
    "            with open(out_f,'w') as f:\n",
    "                json.dump(save_res,f,indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f984d36c-e23e-4964-be86-848284d0ed71",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_f_rephrasing = \"/home/songyan/Real_M2L-main/data/data_finetune/eval/end-to-end-data/result_4_3_rephrasing.json\"\n",
    "# out_f_no_rephrasing = \"/home/songyan/Real_M2L-main/data/data_finetune/eval/end-to-end-data/result_4_3_no_rephrasing.json\"\n",
    "\n",
    "generate_songs(out_f_rephrasing)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (finetune)",
   "language": "python",
   "name": "finetune"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
